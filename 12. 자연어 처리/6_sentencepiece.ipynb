{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Sentencepiece : NSMC 데이터로 tokenizer 구성해보기\n",
    ": https://github.com/google/sentencepiece  \n",
    "\n",
    "내부 단어 분리를 위한 유용한 패키지: 구글의 센텐스피스(Sentencepiece)\n",
    "- 이 때는 하루에 너무 많은 패키지를 사용해서 휙휙 지나갔는데, 음성인식에서 한번 더 만났다\n",
    "- 정말 유명한 패키지인가보다\n",
    "- 자연어 처리는 다소 간단했으나, 음성인식때는 꽤 고생했다\n",
    "- tokenizing을 하는게 쉽지 않았는데 sentencepiece는 이렇게나 간단하다니......\n",
    "- 그래도 재미있었다 !\n",
    "- ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting sentencepiece\n",
      "  Obtaining dependency information for sentencepiece from https://files.pythonhosted.org/packages/a2/f6/587c62fd21fc988555b85351f50bbde43a51524caafd63bc69240ded14fd/sentencepiece-0.2.0-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading sentencepiece-0.2.0-cp311-cp311-win_amd64.whl.metadata (8.3 kB)\n",
      "Downloading sentencepiece-0.2.0-cp311-cp311-win_amd64.whl (991 kB)\n",
      "   ---------------------------------------- 0.0/991.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 10.2/991.5 kB ? eta -:--:--\n",
      "   --- ------------------------------------ 92.2/991.5 kB 1.7 MB/s eta 0:00:01\n",
      "   --------------------------------------- 991.5/991.5 kB 10.4 MB/s eta 0:00:00\n",
      "Installing collected packages: sentencepiece\n",
      "Successfully installed sentencepiece-0.2.0\n"
     ]
    }
   ],
   "source": [
    "! pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sentencepiece as spm\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 읽어오기 : ratings_train.txt\n",
    "naver_df = pd.read_table('./data/ratings_train.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# Null 값 제거 / 확인\n",
    "print(naver_df['document'].isnull().sum())\n",
    "naver_df = naver_df.dropna(how='any')\n",
    "print(naver_df.isnull().values.any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최종적으로 전처리된 텍스트를 'naver_review.txt'에 저장 (문장 \\n 구분)\n",
    "with open('./data/naver_review.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write('\\n'.join(naver_df['document']))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습하기: 2개 파일 생성 .vocab (subword), .model\n",
    "spm.SentencePieceTrainer.Train('--input=./data/naver_review.txt --model_prefix=naver --vocab_size=5000 --model_type=bpe --max_sentence_lengh = 9999')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>734</th>\n",
       "      <td>치는</td>\n",
       "      <td>-731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4701</th>\n",
       "      <td>낰</td>\n",
       "      <td>-4698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4190</th>\n",
       "      <td>탑</td>\n",
       "      <td>-4187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4714</th>\n",
       "      <td>힝</td>\n",
       "      <td>-4711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>▁초</td>\n",
       "      <td>-269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3438</th>\n",
       "      <td>람</td>\n",
       "      <td>-3435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1333</th>\n",
       "      <td>▁잘봤</td>\n",
       "      <td>-1330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1077</th>\n",
       "      <td>▁더빙</td>\n",
       "      <td>-1074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2287</th>\n",
       "      <td>해주는</td>\n",
       "      <td>-2284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2370</th>\n",
       "      <td>▁좋았는데</td>\n",
       "      <td>-2367</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0     1\n",
       "734      치는  -731\n",
       "4701      낰 -4698\n",
       "4190      탑 -4187\n",
       "4714      힝 -4711\n",
       "272      ▁초  -269\n",
       "3438      람 -3435\n",
       "1333    ▁잘봤 -1330\n",
       "1077    ▁더빙 -1074\n",
       "2287    해주는 -2284\n",
       "2370  ▁좋았는데 -2367"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vocab 파일 확인해보기\n",
    "vocab_list = pd.read_csv('./data/naver.vocab', sep='\\t', header=None, quoting=csv.QUOTE_NONE)\n",
    "vocab_list.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 로드\n",
    "sp = spm.SentencePieceProcessor()\n",
    "sp.load('./data/naver.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "집에 가고 싶다\n",
      "['▁집', '에', '▁가', '고', '▁싶다']\n",
      "[467, 3301, 46, 3293, 763]\n",
      "\n",
      "하지만 오늘은 즐거운 금요일\n",
      "['▁하지만', '▁오늘', '은', '▁즐거', '운', '▁금', '요', '일']\n",
      "[509, 960, 3310, 1566, 3405, 1715, 3318, 3379]\n",
      "\n",
      "흐엉엉....\n",
      "['▁흐', '엉', '엉', '....']\n",
      "[953, 3731, 3731, 30]\n",
      "\n",
      "이럴수가.... 이렇게 간단하게 할 수 있다니\n",
      "['▁이', '럴', '수가', '....', '▁이렇게', '▁간', '단', '하게', '▁할', '▁수', '▁있다', '니']\n",
      "[6, 3954, 622, 30, 249, 486, 3477, 104, 218, 60, 449, 3319]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 모델을 통해 tokenizing\n",
    "lines = [\n",
    "    \"집에 가고 싶다\",\n",
    "    \"하지만 오늘은 즐거운 금요일\",\n",
    "    \"흐엉엉....\",\n",
    "    \"이럴수가.... 이렇게 간단하게 할 수 있다니\"\n",
    "]\n",
    "\n",
    "for line in lines:\n",
    "    print(line)\n",
    "    print(sp.encode_as_pieces(line))\n",
    "    print(sp.encode_as_ids(line))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델로 voca size 확인하기\n",
    "sp.GetPieceSize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'듦'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# id to subword\n",
    "sp.IdToPiece(4444)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "953\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# subword to id\n",
    "print(sp.PieceToId('▁흐')) # 언더바 아님!\n",
    "print(sp.PieceToId('_흐'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'하지만 오늘은 즐거운 금요일'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ids to subwords\n",
    "sp.DecodeIds([509, 960, 3310, 1566, 3405, 1715, 3318, 3379])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'이럴수가.... 이렇게 간단하게 할 수 있다니'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# subwords to 원형\n",
    "sp.DecodePieces(['▁이', '럴', '수가', '....', '▁이렇게', '▁간', '단', '하게', '▁할', '▁수', '▁있다', '니'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁집', '에', '▁가', '고', '▁싶다', '...', 'z', 'z', 'z', 'z', 'z', 'z', 'z', 'ᄏᄏᄏᄏ']\n",
      "[467, 3301, 46, 3293, 763, 8, 4138, 4138, 4138, 4138, 4138, 4138, 4138, 71]\n"
     ]
    }
   ],
   "source": [
    "# encode 메소드 중 out_type 인자를 통해: subwords, ids로 변환\n",
    "print(sp.Encode(\"집에 가고 싶다...zzzzzzzㅋㅋㅋㅋ\", out_type=str))\n",
    "print(sp.Encode(\"집에 가고 싶다...zzzzzzzㅋㅋㅋㅋ\", out_type=int))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
