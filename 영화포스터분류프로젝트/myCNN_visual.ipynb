{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 해당 코드는 천재교육 빅데이터 7기 프로젝트로 시행한 CNN 모델 구축입니다\n",
    "---\n",
    "\n",
    "- 빅데이터 이미지 처리 강의를 수강하며 진행한 프로젝트 ( 5/8 ~ 5/10)\n",
    "- 1조 조장을 맡아 팀을 인솔, 자체 CNN모델을 구축\n",
    "- 우리 조는 자체 CNN 모델을 구축하고, ResNet18을 이용한 두 가지 형상을 서로 비교하였다\n",
    "- 캐글의 영화 포스터 이미지 분류 사용\n",
    "- https://www.kaggle.com/datasets/zulkarnainsaurav/four-genre-movie-poster-images\n",
    "- 같이 함께 해준 팀원들 덕분에 voted도 받고 메달도 받았다 ! 와 !\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 발표 피드백\n",
    "- 조금 더 진중한 모습으로 할 것 !\n",
    "- ppt 안에 있는 용어들은 모두 숙지 > 지역 최적점과 글로벌 최적점은 무엇인가?\n",
    "- 대명사 사용 지양 (이것, 저것)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "The annotations are in Korean.  \n",
    "If you want to see it in English, use ChatGPT!  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 라이브러리 불러오기\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 데이터셋 경로 및 클래스 레이블 정의\n",
    "root_dir = r\"YourFolderName\"\n",
    "class_labels = ['action', 'comedy', 'horror', 'romance'] # 데이터 라벨(target)\n",
    "image_extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.gif', '.tiff'] # 이미지 확장자\n",
    "crop_size = 100 # 데이터 증강을 위한 이미지 크롭 사이즈 정의\n",
    "\n",
    "# 이미지 크롭 함수\n",
    "def crop_image(image, crop_size):\n",
    "    height, width = image.shape[:2]\n",
    "    center_x = width // 2\n",
    "    center_y = height // 2\n",
    "    x1 = center_x - crop_size // 2\n",
    "    x2 = center_x + crop_size // 2\n",
    "    y1 = center_y - crop_size // 2\n",
    "    y2 = center_y + crop_size // 2\n",
    "    return image[y1:y2, x1:x2]\n",
    "\n",
    "# 이미지 플립 함수\n",
    "def flip_image(image, flip_code):\n",
    "    return cv2.flip(image, flip_code)\n",
    "\n",
    "# 이미지 회전 함수\n",
    "def rotate_image(image, angle):\n",
    "    height, width = image.shape[:2]\n",
    "    center = (width // 2, height // 2)\n",
    "    matrix = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "    rotated_image = cv2.warpAffine(image, matrix, (width, height))\n",
    "    return rotated_image\n",
    "\n",
    "# 각 클래스별로 이미지 변환 수행\n",
    "for class_label in class_labels:\n",
    "    class_dir = os.path.join(root_dir, class_label)\n",
    "    os.makedirs(class_dir, exist_ok=True)\n",
    "\n",
    "    for image_file in os.listdir(class_dir):\n",
    "        if os.path.splitext(image_file)[1].lower() not in image_extensions:\n",
    "            continue\n",
    "\n",
    "        image_path = os.path.join(class_dir, image_file)\n",
    "        image = cv2.imread(image_path)\n",
    "\n",
    "        # 왼쪽으로 15도 회전한 이미지 저장\n",
    "        rotated_left_image = rotate_image(image, -15)\n",
    "        cv2.imwrite(os.path.join(class_dir, f\"rotated_left{image_file}\"), rotated_left_image)\n",
    "\n",
    "        # 오른쪽으로 15도 회전한 이미지 저장\n",
    "        rotated_right_image = rotate_image(image, 15)\n",
    "        cv2.imwrite(os.path.join(class_dir, f\"rotated_right{image_file}\"), rotated_right_image)\n",
    "\n",
    "        # 좌우 반전한 이미지 저장\n",
    "        flipped_horizontal_image = flip_image(image, 1)\n",
    "        cv2.imwrite(os.path.join(class_dir, f\"flipped_horizontal{image_file}\"), flipped_horizontal_image)\n",
    "\n",
    "        # 크롭된 이미지 저장\n",
    "        cropped_image = crop_image(image, crop_size)\n",
    "        cv2.imwrite(os.path.join(class_dir, f\"cropped{image_file}\"), cropped_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training images: 5220\n",
      "Number of testing images: 1305\n"
     ]
    }
   ],
   "source": [
    "# 이미지 데이터셋의 루트 디렉토리 정의\n",
    "root_dir = r\"YourFolderName\"\n",
    "\n",
    "# 레이블(장르 이름)의 목록 가져오기\n",
    "labels = os.listdir(root_dir)\n",
    "\n",
    "# 이미지 경로와 해당하는 레이블 저장 리스트 정의\n",
    "image_paths = []\n",
    "labels_list = []\n",
    "\n",
    "# 각 레이블(장르)에 대해 반복\n",
    "for label in labels:\n",
    "    # 레이블 디렉토리의 경로 가져옴\n",
    "    label_dir = os.path.join(root_dir, label)\n",
    "    # 디렉토리가 존재하는지 확인\n",
    "    if os.path.isdir(label_dir):\n",
    "        # 레이블 디렉토리에 있는 이미지 파일 목록 가져오기\n",
    "        images = os.listdir(label_dir)\n",
    "        # 이미지 경로를 리스트에 추가\n",
    "        image_paths.extend([os.path.join(label_dir, img) for img in images])\n",
    "        # 해당하는 레이블을 레이블 리스트에 추가\n",
    "        labels_list.extend([label] * len(images))\n",
    "    else:\n",
    "        print(f\"Warning: Directory {label_dir} not found.\")\n",
    "\n",
    "# 데이터 확인\n",
    "if len(image_paths) == 0:\n",
    "    raise ValueError(\"No images found in the dataset.\")\n",
    "\n",
    "# 각 레이블의 비율을 유지하면서 데이터를 훈련 세트와 테스트 세트로 분할\n",
    "if len(labels_list) > 0:\n",
    "    train_paths, test_paths, train_labels, test_labels = train_test_split(image_paths, labels_list, test_size=0.2, random_state=42, stratify=labels_list)\n",
    "else:\n",
    "    raise ValueError(\"No labels found for the images.\")\n",
    "print(\"Number of training images:\", len(train_paths))\n",
    "print(\"Number of testing images:\", len(test_paths))\n",
    "\n",
    "# 각 장르의 이미지 폴더 경로 정의\n",
    "train_data_dir = r\"YourFolderName\\train\"\n",
    "test_data_dir = r\"YourFolderName\\test\"\n",
    "\n",
    "# 훈련 및 테스트 데이터의 디렉토리 생성\n",
    "os.makedirs(train_data_dir, exist_ok=True)\n",
    "os.makedirs(test_data_dir, exist_ok=True)\n",
    "\n",
    "# 이미지를 훈련 및 테스트 디렉토리로 이동\n",
    "for i in range(len(train_paths)):\n",
    "    label = train_labels[i]\n",
    "    image = train_paths[i]\n",
    "    dst = os.path.join(train_data_dir, label, os.path.basename(image))\n",
    "    os.makedirs(os.path.dirname(dst), exist_ok=True)\n",
    "    os.replace(image, dst)\n",
    "for i in range(len(test_paths)):\n",
    "    label = test_labels[i]\n",
    "    image = test_paths[i]\n",
    "    dst = os.path.join(test_data_dir, label, os.path.basename(image))\n",
    "    os.makedirs(os.path.dirname(dst), exist_ok=True)\n",
    "    os.replace(image, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 생성기 정의와 데이터 증강을 위한 데이터 생성기 설정\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# 훈련 및 테스트 데이터셋 생성\n",
    "train_generator = train_datagen.flow_from_directory(train_data_dir,\n",
    "                                                    target_size=(224, 224),\n",
    "                                                    batch_size=100,\n",
    "                                                    class_mode='categorical')\n",
    "test_generator = test_datagen.flow_from_directory(test_data_dir,\n",
    "                                                  target_size=(224, 224),\n",
    "                                                  batch_size=1000,\n",
    "                                                  class_mode='categorical')\n",
    "\n",
    "# 모델 정의\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(256, (3, 3), activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(4, activation='softmax')\n",
    "])\n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=tf.keras.optimizers.Adam(learning_rate=0.00005),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 모델 훈련\n",
    "history = model.fit(train_generator,\n",
    "                    epochs=10,\n",
    "                    validation_data=test_generator)\n",
    "\n",
    "# Plot training and validation accuracy\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot training and validation loss\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 클래스 레이블 가져오기\n",
    "class_labels = train_generator.class_indices\n",
    "\n",
    "# 인덱스로부터 레이블을 얻기 위해 딕셔너리 뒤집기\n",
    "labels = dict((v,k) for k,v in class_labels.items())\n",
    "\n",
    "# 이미지 예측 및 출력하는 함수 정의\n",
    "def predict_images(model, generator, labels, num_images=6):\n",
    "    # 데이터 생성기에서 이미지와 레이블 배치 가져오기\n",
    "    image_batch, label_batch = next(generator)\n",
    "    # 이미지에 대한 클래스 예측\n",
    "    predictions = model.predict(image_batch)\n",
    "    # 예측된 레이블과 함께 이미지 출력\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    for i in range(num_images):\n",
    "        plt.subplot(1, num_images, i+1)\n",
    "        plt.imshow(image_batch[i])\n",
    "        predicted_label = labels[np.argmax(predictions[i])]\n",
    "        true_label = labels[np.argmax(label_batch[i])]\n",
    "        if predicted_label == true_label:\n",
    "            title_color = 'green'  # True prediction (green color)\n",
    "        else:\n",
    "            title_color = 'red'    # Wrong prediction (red color)\n",
    "        plt.title(f\"Predicted: {predicted_label}\\nTrue: {true_label}\", fontsize=10, color=title_color)\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "# 함수 호출하여 예측된 이미지 출력\n",
    "predict_images(model, test_generator, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![-](https://github.com/PlutoJoshua/Education_CJ/blob/main/%EC%98%81%ED%99%94%ED%8F%AC%EC%8A%A4%ED%84%B0%EB%B6%84%EB%A5%98%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8/%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202024-05-13%20172355.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![-](https://github.com/PlutoJoshua/Education_CJ/blob/main/%EC%98%81%ED%99%94%ED%8F%AC%EC%8A%A4%ED%84%B0%EB%B6%84%EB%A5%98%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8/%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202024-05-13%20174045.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "ResNet19은 캐글에 있습니다.  \n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
